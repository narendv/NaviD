# Example evaluation configuration
# This shows how to set up evaluation for a trained model

project_name: navigation_eval
run_name: eval_example

# Model configuration (must match training config)
model_type: nomad  # or "vint", "gnm"
vision_encoder: nomad_vint
encoding_size: 256
context_size: 3
context_type: temporal

# Evaluation settings
use_wandb: false  # Set to true if you want to log to wandb
eval_batch_size: 32
gpu_ids: [0]
num_workers: 4

# Model architecture (must match training)
mha_num_attention_heads: 4
mha_num_attention_layers: 4
mha_ff_dim_factor: 4
down_dims: [64, 128, 256]
num_diffusion_iters: 10
cond_predict_scale: false

# Data processing parameters (must match training)
image_size: [96, 96]
normalize: true
len_traj_pred: 8
learn_angle: false
goal_type: image

# Distance and action bounds (must match training)
distance:
  min_dist_cat: 0
  max_dist_cat: 20
action:
  min_dist_cat: 3
  max_dist_cat: 20

# Goal masking (for NoMaD)
goal_mask_prob: 0.5

# Datasets to evaluate on
datasets:
  recon:
    data_folder: /path/to/your/recon/dataset
    test: /path/to/your/data_splits/recon/test/
    end_slack: 3
    goals_per_obs: 1
    negative_mining: true
    waypoint_spacing: 1
    
  # Add more datasets as needed
  # your_dataset:
  #   data_folder: /path/to/dataset
  #   test: /path/to/test/split
  #   end_slack: 0
  #   goals_per_obs: 1
  #   negative_mining: true

# Logging and visualization
print_log_freq: 100
wandb_log_freq: 10
image_log_freq: 1000
num_images_log: 8